<script setup>
import { useHead } from '@vueuse/head'

useHead({
  title: 'Безопасность и защита данных при работе с AI – IntellectShop',
  meta: [
    {
      name: 'description',
      content: 'Как защитить корпоративные данные при использовании облачных AI-моделей и API. Внедрение локальных решений и контроль доступа.',
    },
  ],
})
</script>

<template>
  <section class="max-w-3xl mx-auto px-4 py-10">
    <h1 class="text-2xl font-bold mb-4">Безопасность и защита данных при работе с AI</h1>

    <p class="text-gray-700 mb-4">
      Использование нейросетей и AI-инструментов открывает большие возможности, но требует осторожности при работе с конфиденциальной информацией. На этом тренинге вы узнаете, как обезопасить корпоративные данные при интеграции с облачными AI-сервисами и как внедрять локальные решения.
    </p>

    <h2 class="text-lg font-semibold mb-2">Что входит в обучение</h2>
    <ul class="list-disc pl-5 text-gray-700 mb-6 space-y-1">
      <li>Обзор рисков при использовании ChatGPT, Gemini, Claude, Copilot и других AI</li>
      <li>Выбор безопасных моделей: GPT, Mistral, LLaMA — и где их запускать</li>
      <li>Подключение к облачным API: как избежать утечек данных</li>
      <li>Изоляция чувствительных данных: подходы к анонимизации и шифрованию</li>
      <li>Контроль использования: запрет на пересылку персональных и коммерческих данных</li>
      <li>Аудит обращений к API: кто, когда и какие данные отправляет</li>
      <li>Локальные LLM: как развернуть собственную нейросеть на сервере или ноутбуке</li>
    </ul>

    <h2 class="text-lg font-semibold mb-2">Типичные риски и проблемы</h2>
    <ul class="list-disc pl-5 text-gray-700 mb-6 space-y-1">
      <li>Персональные данные сотрудников или клиентов попадают в облако</li>
      <li>ChatGPT используется для обработки чувствительных документов</li>
      <li>Невозможно отследить, какие запросы отправляют сотрудники</li>
      <li>Недостаток прозрачности в политике OpenAI, Google и Anthropic</li>
      <li>Отсутствие инструкций для безопасной работы с AI</li>
    </ul>

    <h2 class="text-lg font-semibold mb-2">Что вы получите на выходе</h2>
    <p class="text-gray-700 mb-6">
      Вы научитесь настраивать безопасную работу с нейросетями и API, внедрите практики защиты данных и сможете контролировать, как используются AI-инструменты в компании. Это особенно важно для организаций в сфере юриспруденции, медицины, финансов и госструктур.
    </p>

    <h2 class="text-lg font-semibold mb-2">2 лайфхака по безопасности</h2>
    <ul class="list-disc pl-5 text-gray-700 mb-6 space-y-1">
      <li><strong>Прокси для API:</strong> настройте промежуточный сервер, который будет фильтровать запросы к AI и логировать действия.</li>
      <li><strong>Внедрение фильтров:</strong> используйте RegExp или модели-модераторы для блокировки определённых типов запросов.</li>
    </ul>

    <p class="text-gray-700 italic">
      ИИ должен работать на вас — а не раскрывать вашу информацию. Мы покажем, как использовать возможности AI, не рискуя корпоративной безопасностью.
    </p>
  </section>
</template>